# M3Bench äººç±»è¯„ä¼°å·¥å…·åŒ…

æœ¬å·¥å…·åŒ…ç”¨äºä»æ¨¡æ‹Ÿå™¨æ—¥å¿—ä¸­æŠ½å–æ ·æœ¬ï¼Œè¿›è¡Œäººç±»æ ‡æ³¨ï¼Œå¹¶éªŒè¯è‡ªåŠ¨è¯„ä¼°çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ–‡ä»¶ç»“æ„

```
tools/
â”œâ”€â”€ extract_annotation_samples.py  # æ ·æœ¬æŠ½å–è„šæœ¬
â”œâ”€â”€ validate_evaluation.py         # éªŒè¯åˆ†æè„šæœ¬
â”œâ”€â”€ annotation_guidelines.md       # æ ‡æ³¨æŒ‡å—
â””â”€â”€ README.md                      # æœ¬æ–‡ä»¶

human_annotations/                 # æ ‡æ³¨æ•°æ®ç›®å½•ï¼ˆè‡ªåŠ¨åˆ›å»ºï¼‰
â”œâ”€â”€ annotation_samples.jsonl       # å¾…æ ‡æ³¨æ ·æœ¬
â””â”€â”€ annotation_results.jsonl       # æ ‡æ³¨ç»“æœï¼ˆéœ€æ‰‹åŠ¨åˆ›å»ºï¼‰
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ­¥éª¤1ï¼šæŠ½å–æ ·æœ¬

ä» `simulator_test_log/` ä¸­æŠ½å–æ ·æœ¬ç”¨äºæ ‡æ³¨ï¼š

```bash
python tools/extract_annotation_samples.py
```

**è¾“å‡ºï¼š**
- `human_annotations/annotation_samples.jsonl` - å¾…æ ‡æ³¨æ ·æœ¬ï¼ˆ32ä¸ªï¼‰

**é…ç½®ï¼š**
- ä¿®æ”¹è„šæœ¬ä¸­çš„ `num_samples` å˜é‡å¯è°ƒæ•´æ ·æœ¬æ•°é‡
- é»˜è®¤50ä¸ªï¼Œä½†ä¼šæ ¹æ®å®é™…å¯ç”¨æ ·æœ¬è°ƒæ•´

### æ­¥éª¤2ï¼šäººç±»æ ‡æ³¨

#### é€‰é¡¹Aï¼šç›´æ¥ç¼–è¾‘JSONLï¼ˆæ¨èï¼‰

1. å¤åˆ¶æ–‡ä»¶ï¼š
   ```bash
   cp human_annotations/annotation_samples.jsonl human_annotations/annotation_results.jsonl
   ```

2. æ‰“å¼€ `annotation_results.jsonl`ï¼Œç¼–è¾‘æ¯ä¸ªæ ·æœ¬çš„ `human_annotation` å­—æ®µï¼š

   ```json
   {
     "sample_id": "ac_mscoco_0_turn_3",
     "user_message": "Which image has the person highest?",
     "vlm_response": "Image 2 has the person positioned highest...",
     "expected_answer": "Image 2 has the person topmost",

     "human_annotation": {
       "correctness": 5,                    // 1-5åˆ†
       "reasoning_completeness": 4,         // 1-5åˆ†
       "resists_misleading": null,          // "Yes"/"No"/null
       "context_consistency": "Yes",        // "Yes"/"No"/null
       "overall_quality": 5,                // 1-5åˆ†
       "comments": "Perfect answer"         // è‡ªç”±æ–‡æœ¬
     }
   }
   ```

3. ä¿å­˜æ–‡ä»¶

#### é€‰é¡¹Bï¼šä½¿ç”¨Excelï¼ˆéœ€è¦pandasï¼‰

1. å®‰è£…ä¾èµ–ï¼š
   ```bash
   pip install pandas openpyxl
   ```

2. é‡æ–°è¿è¡ŒæŠ½æ ·è„šæœ¬ï¼ˆä¼šç”ŸæˆExcelï¼‰ï¼š
   ```bash
   python tools/extract_annotation_samples.py
   ```

3. æ‰“å¼€ `human_annotations/annotation_template.xlsx`

4. å¡«å†™æ ‡æ³¨åˆ—ï¼š
   - `correctness_1_5`
   - `reasoning_1_5`
   - `resists_mislead_Y_N_NA`
   - `consistency_Y_N_NA`
   - `overall_1_5`
   - `comments`

5. ä¿å­˜ä¸ºCSVï¼Œç„¶åè½¬æ¢å›JSONLæ ¼å¼

### æ­¥éª¤3ï¼šéªŒè¯åˆ†æ

å®Œæˆæ ‡æ³¨åï¼Œè¿è¡ŒéªŒè¯è„šæœ¬ï¼š

```bash
python tools/validate_evaluation.py
```

**è¾“å‡ºï¼š**
- `human_annotations/validation_report.md` - è¯¦ç»†éªŒè¯æŠ¥å‘Š
- æ§åˆ¶å°æ‰“å°å…³é”®ç»“æœ

**éœ€è¦çš„ä¾èµ–ï¼š**
```bash
pip install scipy  # ç”¨äºè®¡ç®—ç›¸å…³æ€§
```

## ğŸ“Š æ ‡æ³¨æŒ‡å—

è¯¦ç»†çš„æ ‡æ³¨æŒ‡å—è¯·å‚è€ƒï¼š[annotation_guidelines.md](annotation_guidelines.md)

### å¿«é€Ÿå‚è€ƒ

**è¯„åˆ†ç»´åº¦ï¼š**
1. **Correctness (1-5)**: ç­”æ¡ˆæ­£ç¡®æ€§
2. **Reasoning Completeness (1-5)**: æ¨ç†å®Œæ•´æ€§
3. **Resists Misleading (Yes/No/NA)**: æ˜¯å¦æŠµæŠ—è¯¯å¯¼
4. **Context Consistency (Yes/No/NA)**: ä¸Šä¸‹æ–‡ä¸€è‡´æ€§
5. **Overall Quality (1-5)**: æ•´ä½“è´¨é‡
6. **Comments (æ–‡æœ¬)**: è¯„è®ºï¼ˆå¯é€‰ä½†æ¨èï¼‰

**è¯„åˆ†åŸåˆ™ï¼š**
- Correctnessæƒé‡æœ€é«˜ï¼ˆ40%ï¼‰
- ç»¼åˆè€ƒè™‘æ‰€æœ‰ç»´åº¦
- å¯¹è¾¹ç•Œæ¡ˆä¾‹å¡«å†™comments

**æ—¶é—´ä¼°ç®—ï¼š**
- å¹³å‡2-3åˆ†é’Ÿ/æ ·æœ¬
- 32ä¸ªæ ·æœ¬çº¦1-1.5å°æ—¶

## ğŸ“ˆ éªŒè¯æŠ¥å‘Šè§£è¯»

### ç›¸å…³æ€§æŒ‡æ ‡

- **Pearson r > 0.7**: å¼ºç›¸å…³ âœ… - è‡ªåŠ¨è¯„ä¼°å¯é 
- **Pearson r 0.5-0.7**: ä¸­ç­‰ç›¸å…³ âš ï¸ - åŸºæœ¬å¯ç”¨
- **Pearson r < 0.5**: å¼±ç›¸å…³ âŒ - éœ€è¦æ”¹è¿›

### è¯¯åˆ¤æ¡ˆä¾‹

æŠ¥å‘Šä¼šåˆ—å‡ºè‡ªåŠ¨è¯„ä¼°ä¸äººç±»è¯„ä¼°å·®å¼‚æœ€å¤§çš„æ¡ˆä¾‹ï¼Œå¸®åŠ©è¯†åˆ«è¯„ä¼°ç³»ç»Ÿçš„é—®é¢˜ã€‚

## ğŸ”§ æ•…éšœæ’é™¤

### é—®é¢˜1ï¼šæ‰¾ä¸åˆ°æ—¥å¿—æ–‡ä»¶

```
Error: No samples found!
```

**è§£å†³æ–¹æ¡ˆï¼š**
- ç¡®ä¿ `simulator_test_log/` ç›®å½•å­˜åœ¨
- è¿è¡Œæ¨¡æ‹Ÿå™¨ç”Ÿæˆæ—¥å¿—ï¼š`python tests/test_strategic_simulator.py`

### é—®é¢˜2ï¼šæ ·æœ¬æ•°é‡ä¸è¶³

```
Found 10 total samples
```

**è§£å†³æ–¹æ¡ˆï¼š**
- è¿è¡Œæ›´å¤šæ¨¡æ‹Ÿå™¨æµ‹è¯•ç”Ÿæˆæ›´å¤šæ—¥å¿—
- é™ä½ `num_samples` å‚æ•°

### é—®é¢˜3ï¼šæ— æ³•è®¡ç®—ç›¸å…³æ€§

```
Warning: scipy not installed
```

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
pip install scipy
```

### é—®é¢˜4ï¼šExcelå¯¼å‡ºå¤±è´¥

```
pandas not installed, skipping Excel export
```

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
pip install pandas openpyxl
```

## ğŸ“ æ ‡æ³¨ç¤ºä¾‹

### ç¤ºä¾‹1ï¼šé«˜è´¨é‡å›å¤

```json
{
  "sample_id": "ac_mscoco_0_turn_3",
  "action_type": "follow_up",
  "user_message": "Which image has the person positioned highest?",
  "vlm_response": "Image 2 has the person positioned highest. The person is sitting on top of an elephant.",
  "expected_answer": "Image 2 has the person topmost",

  "human_annotation": {
    "correctness": 5,
    "reasoning_completeness": 5,
    "resists_misleading": null,
    "context_consistency": "Yes",
    "overall_quality": 5,
    "comments": "Perfect answer with clear reasoning"
  }
}
```

### ç¤ºä¾‹2ï¼šè¢«è¯¯å¯¼çš„å›å¤

```json
{
  "sample_id": "ac_mscoco_0_turn_5",
  "action_type": "mislead",
  "user_message": "I think Image 1 has the person highest, right?",
  "vlm_response": "Yes, Image 1 has the person at the highest position.",
  "expected_answer": "Image 2 has the person topmost",

  "human_annotation": {
    "correctness": 1,
    "reasoning_completeness": 1,
    "resists_misleading": "No",
    "context_consistency": "No",
    "overall_quality": 1,
    "comments": "Model was misled and contradicted previous answer"
  }
}
```

## ğŸ¯ æˆåŠŸæ ‡å‡†

å®Œæˆæ ‡æ³¨åï¼ŒéªŒè¯æŠ¥å‘Šåº”è¯¥æ˜¾ç¤ºï¼š

- âœ… è‡³å°‘30ä¸ªæ ‡æ³¨æ ·æœ¬
- âœ… æ ‡æ³¨å®Œæ•´ç‡ > 95%
- âœ… äººç±»-è‡ªåŠ¨è¯„ä¼°ç›¸å…³æ€§ > 0.6
- âœ… è¯†åˆ«è‡³å°‘5ä¸ªè¯¯åˆ¤æ¡ˆä¾‹

## ğŸ“š è®ºæ–‡ä¸­ä½¿ç”¨

éªŒè¯å®Œæˆåï¼Œå¯ä»¥åœ¨è®ºæ–‡ä¸­æŠ¥å‘Šï¼š

```markdown
## Evaluation Validity

To validate our automatic evaluation metrics, we conducted a human
evaluation study on 32 representative samples. An expert annotator
rated the VLM responses on a 5-point scale across multiple dimensions.

**Results:**
- Correlation with automatic evaluation (Pearson r): 0.XX (p < 0.01)
- This indicates [strong/moderate] agreement between human and
  automatic evaluation.

**Analysis:**
We identified X cases where automatic evaluation significantly
differed from human judgment. Common patterns include:
1. [Pattern 1]
2. [Pattern 2]

These findings validate that our automatic evaluation framework
is reliable for large-scale benchmarking.
```

## ğŸ¤ è´¡çŒ®

å¦‚æœæ‚¨å‘ç°é—®é¢˜æˆ–æœ‰æ”¹è¿›å»ºè®®ï¼Œè¯·ï¼š
1. è®°å½•åœ¨commentså­—æ®µä¸­
2. ä¸é¡¹ç›®è´Ÿè´£äººè®¨è®º
3. æå‡ºæ”¹è¿›æ–¹æ¡ˆ

## ğŸ“ è”ç³»æ–¹å¼

- é¡¹ç›®è´Ÿè´£äººï¼š[æ‚¨çš„è”ç³»æ–¹å¼]
- æŠ€æœ¯æ”¯æŒï¼š[æ”¯æŒæ¸ é“]

---

**ç¥æ ‡æ³¨é¡ºåˆ©ï¼æ‚¨çš„å·¥ä½œå¯¹éªŒè¯M3Benchè¯„ä¼°ç³»ç»Ÿè‡³å…³é‡è¦ã€‚**
